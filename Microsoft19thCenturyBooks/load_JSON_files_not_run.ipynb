{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"jumbotron jumbotron-fluid\">\n",
    "  <div class=\"container\">\n",
    "    <h1 class=\"display-4\">Load JSON files from a directory (and sub-directories)</h1>\n",
    "    <p class=\"lead\">Examples on how to load the full text from JSON files stored in a certain local directory (and sub-directories) of from a file downloaded from a URL.</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/BL-Labs/Jupyter-notebooks-projects-using-BL-Sources/blob/master/Microsoft19thCenturyBooks/load_JSON_files_not_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this Notebook:\n",
    "\n",
    " * Read JSON files containg full text: from local zip file or downloaded from a URL;\n",
    " * Loaded the contents of the several JSON files, even in several sub-directories, into a big DataFrame;\n",
    " * Add ALEPH SYS ID of the book (\"bookid\") and the Volume information extracted from the filename of each JSON file;\n",
    " * Exclude blocks of text that are empty;\n",
    " * Search for block of text that mention \"London\";\n",
    " * From those, search the ones who have the term \"love\";\n",
    " * Display a couple of those block of texts;\n",
    " * Retrieve the BookID and Volume to which those blocks of text belong to;\n",
    " * Link to their catalog record on BL Explorer.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "#### Notes:\n",
    "\n",
    "* If using BINDER or a did a git clone to your Jupyter Notebook LOCAL SERVER, skip cell 1, place the cursor on cell 2 and from the main menu, choose \"Cell\" > \"Run All Bellow\", if not executing cell-by-cell;\n",
    "\n",
    "* If using Google Colab, with the cursor on the first cell, from the main menu, choose \"Runtime\" > \"Run after\", if not executing cell-by-cell.\n",
    "</div> \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only RUN this CELL if using Google COLAB\n",
    "# To download the zip file (295MB), it could take from 10 to 30 minutes\n",
    "# Not needed if using BINDER or a did a git clone to your Jupyter Notebook LOCAL SERVER, as you already have the data locally\n",
    "\n",
    "!wget https://cld.pt/dl/download/b2d718a4-2aa2-496c-aad8-d889f27a4be2/dig19cbooksjsontext_sample.zip\n",
    "\n",
    "# Only RUN THE UNZIP ONCE, please\n",
    "!unzip dig19cbooksjsontext_sample.zip \n",
    "\n",
    "!mkdir data\n",
    "!mv dig19cbooksjsontext/ data/dig19cbooksjsontext/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary modules / Libraries:\n",
    "\n",
    "import os, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the files in this Directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all the files are under the same directory a simpler way to locate them would be:\n",
    "# path_to_json = 'data/dig19cbooksjsontext/json/0037/'\n",
    "# json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "\n",
    "#this will locate all the JSON files inside the main Directory and any sub-Folder:\n",
    "path_to_json = 'data/dig19cbooksjsontext/'\n",
    "\n",
    "json_files = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(path_to_json)\n",
    "             for name in files\n",
    "             if name.endswith((\".json\"))] #If we needed to read several files extensions: if name.endswith((\".ext1\", \".ext2\"))\n",
    "\n",
    "print('Number of JSON files ready to be loaded: ' + str(len(json_files)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Path to the first file: '+json_files[0])\n",
    "print('Path to the last file: '+json_files[len(json_files)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files are ready to be loaded into a big DataFrame\n",
    "We will add ALEPH SYS ID of the book (\"bookid\") and the Volume information extracted from the filename of the JSON file.\n",
    "\n",
    "* A similar process can be used to append all the data into a single JSON, instead of loading the data from the JSON files into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons_df = pd.DataFrame()\n",
    "#jsons_df = pd.DataFrame(columns=['indexglob', 'indexlocal', 'text','bookid','volume'])\n",
    "\n",
    "for index, js in enumerate(json_files):\n",
    "    jsons_df_ins = pd.read_json(json_files[index])  #if we were just loading from one Directory, first solution above, we would need to add the path to the file: jsons_df_ins = pd.read_json(path_to_json+json_files[index])\n",
    "    jsons_df_ins[\"bookid\"] = json_files[index][35:44]\n",
    "    jsons_df_ins[\"volume\"] = json_files[index][45:47]\n",
    "    jsons_df = jsons_df.append(jsons_df_ins, ignore_index=True)\n",
    "\n",
    "\n",
    "print('Blocks of text loaded into the DataFrame: ' + str(jsons_df.size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First 20 blocks of text:')\n",
    "jsons_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given that some blocks are empty, let's create a new DataFrame with only the blocks that have Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop blocks of text that are empty\n",
    "\n",
    "filter = jsons_df[1] != \"\"\n",
    "blocksText_df = jsons_df[filter]\n",
    "print('Blocks of text non empty: ' + str(blocksText_df.size))\n",
    "print('Excluded ' + str(jsons_df.size - blocksText_df.size) + ' that are empty')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocksText_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now we can do whatever needed with this DataFrame\n",
    "\n",
    "#### E.g., let's look for blocks of text that mention London:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df = blocksText_df[blocksText_df[1].str.contains(\"London\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(London_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... and of those, have the term \"love\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_love_df = London_df[London_df[1].str.contains(\"love\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(London_love_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check one of the records, ID = 6132 (3rd in the list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_love_df[1][6153]\n",
    "\n",
    "# if using Google COLAB, comment the above and uncoment the bellow, please\n",
    "# London_love_df[1][186]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(...) REMAINS OF ROMAN **LONDON**. THE **LONDON** STONE.... notwithstanding their **love** for old customs and ancient traditions ... \n",
    "\n",
    "or if using Google Colab example:\n",
    "\n",
    "(...) I am come down to take her to **London**, where (...) as the only true **love**r and friend she had (...)\n",
    "\n",
    "#### Retrieve the BookID and Volume to which this block of text belongs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_love_df.loc[6153, ['bookid', 'volume']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also check a random one (a sample of 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_love_df[1].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_love_df[1][347374] # use the index, first number retrieved above -- when ran this time, it gave the index 347374"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(...) St. Paul's cathedral in **London**, it was regarded (...) at that period, so **love**d and reverenced by the people (...)\n",
    "\n",
    "#### And again, let's retrieve the BookID and Volume to which this block of text belongs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_love_df.loc[347374, ['bookid', 'volume']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The bookid is ALEPH SYS number, so we can search it on BL Explorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Link to this book\\'s catalog record at BL explorer:')\n",
    "print('http://explore.bl.uk/primo_library/libweb/action/search.do?cs=frb&doc=BLL'+ London_love_df[\"bookid\"][347374] + '&dscnt=1&scp.scps=scope:(BLCONTENT)&frbg=&tab=local_tab&srt=rank&ct=search&mode=Basic&dum=true&tb=t&indx=1&vl(freeText0)='+ London_love_df[\"bookid\"][347374] + '&fn=search&vid=BLVU1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
