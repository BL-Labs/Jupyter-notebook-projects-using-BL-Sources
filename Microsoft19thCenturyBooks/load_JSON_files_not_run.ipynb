{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "load_JSON_files_not_run.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BL-Labs/Jupyter-notebooks-projects-using-BL-Sources/blob/master/Microsoft19thCenturyBooks/load_JSON_files_not_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZtGZPllwgzX",
        "colab_type": "text"
      },
      "source": [
        "# Load JSON files from a directory (or list of directories)\n",
        "\n",
        "#### Note:\n",
        "* If using BINDER or a did a git clone to your Jupyter Notebook LOCAL SERVER, skip cell 1, place the cursor on cell 2 and from the main menu, choose \"Cell\" > \"Run All Bellow\", if not executing cell-by-cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JWdcoTcwgzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only RUN this CELL if using Google COLAB\n",
        "# To download the zip file (295MB), it could take from 10 to 30 minutes\n",
        "# Not needed if using BINDER or a did a git clone to your Jupyter Notebook LOCAL SERVER, as you already have the data locally\n",
        "\n",
        "!wget https://cld.pt/dl/download/b2d718a4-2aa2-496c-aad8-d889f27a4be2/dig19cbooksjsontext_sample.zip\n",
        "\n",
        "# Only RUN THE UNZIP ONCE, please\n",
        "!unzip dig19cbooksjsontext_sample.zip \n",
        "\n",
        "!mkdir data\n",
        "!mv dig19cbooksjsontext/ data/dig19cbooksjsontext/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4R1Us7Vwgzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the necessary modules / Libraries:\n",
        "\n",
        "import os, json\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyKEsa5wwgzo",
        "colab_type": "text"
      },
      "source": [
        "### Let's check the files in this Directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q932_8oOwgzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If all the files are under the same directory a simpler way to locate them would be:\n",
        "# path_to_json = 'data/dig19cbooksjsontext/json/0037/'\n",
        "# json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
        "\n",
        "#this will locate all the JSON files inside the main Directory and any sub-Folder:\n",
        "path_to_json = 'data/dig19cbooksjsontext/'\n",
        "\n",
        "json_files = [os.path.join(root, name)\n",
        "             for root, dirs, files in os.walk(path_to_json)\n",
        "             for name in files\n",
        "             if name.endswith((\".json\"))] #If we needed to read several files extensions: if name.endswith((\".ext1\", \".ext2\"))\n",
        "\n",
        "print('Number of JSON files ready to be loaded: ' + str(len(json_files)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htm8CmWEwgz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Path to the first file: '+json_files[0])\n",
        "print('Path to the last file: '+json_files[len(json_files)-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JfBO64hwg12",
        "colab_type": "text"
      },
      "source": [
        "### Files are ready to be loaded into a big DataFrame\n",
        "We will add ALEPH SYS ID of the book (\"bookid\") and the Volume information extracted from the filename of the JSON file.\n",
        "\n",
        "* A similar process can be used to append all the data into a single JSON, instead of loading the data from the JSON files into a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N0As27Qwg2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jsons_df = pd.DataFrame()\n",
        "#jsons_df = pd.DataFrame(columns=['indexglob', 'indexlocal', 'text','bookid','volume'])\n",
        "\n",
        "for index, js in enumerate(json_files):\n",
        "    jsons_df_ins = pd.read_json(json_files[index])  #if we were just loading from one Directory, first solution above, we would need to add the path to the file: jsons_df_ins = pd.read_json(path_to_json+json_files[index])\n",
        "    jsons_df_ins[\"bookid\"] = json_files[index][35:44]\n",
        "    jsons_df_ins[\"volume\"] = json_files[index][45:47]\n",
        "    jsons_df = jsons_df.append(jsons_df_ins, ignore_index=True)\n",
        "\n",
        "\n",
        "print('Blocks of text loaded into the DataFrame: ' + str(jsons_df.size))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTFXYROMwg3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('First 20 blocks of text:')\n",
        "jsons_df.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN_hcpk-wg3W",
        "colab_type": "text"
      },
      "source": [
        "### Given that some blocks are empty, let's create a new DataFrame with only the blocks that have Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQy9XhDCwg3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop blocks of text that are empty\n",
        "\n",
        "filter = jsons_df[1] != \"\"\n",
        "blocksText_df = jsons_df[filter]\n",
        "print('Blocks of text non empty: ' + str(blocksText_df.size))\n",
        "print('Excluded ' + str(jsons_df.size - blocksText_df.size) + ' that are empty')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih996z_9wg3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blocksText_df.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln2yWCh8wg3v",
        "colab_type": "text"
      },
      "source": [
        "### And now we can do whatever needed with this DataFrame\n",
        "\n",
        "#### E.g., let's look for blocks of text that mention London:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FRiO83wwg3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "London_df = blocksText_df[blocksText_df[1].str.contains(\"London\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xheItyP_wg36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(London_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGb2sujYwg4I",
        "colab_type": "text"
      },
      "source": [
        "#### ... and of those, have the term \"love\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCEZ7IUPwg4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "London_love_df = London_df[London_df[1].str.contains(\"love\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qBuSVkrwg4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(London_love_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk0hUh79wg4k",
        "colab_type": "text"
      },
      "source": [
        "#### Let's check one of the records, ID = 6132 (3rd in the list)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHfsY7yVwg4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "London_love_df[1][6153]\n",
        "\n",
        "# if using Google COLAB, comment the above and uncoment the bellow, please\n",
        "# London_love_df[1][186]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDXO_epIwg47",
        "colab_type": "text"
      },
      "source": [
        "(...) REMAINS OF ROMAN **LONDON**. THE **LONDON** STONE.... notwithstanding their **love** for old customs and ancient traditions ... \n",
        "\n",
        "or if using Google Colab example:\n",
        "\n",
        "(...) I am come down to take her to **London**, where (...) as the only true **love**r and friend she had (...)\n",
        "\n",
        "#### Retrieve the BookID and Volume to which this block of text belongs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwaEnTMTwg48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "London_love_df.loc[6153, ['bookid', 'volume']]\n",
        "\n",
        "# if using Google COLAB, comment the above and uncoment the bellow, please\n",
        "# London_love_df.loc[186, ['bookid', 'volume']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcsNkSWUwg5F",
        "colab_type": "text"
      },
      "source": [
        "#### We can also check a random one (a sample of 1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvsYmPDkwg5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "London_love_df[1].sample(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw-4fL6ewg5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "London_love_df[1][347374] # use the index, first number retrieved above -- when ran this time, it gave the index 347374"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQXZslx-wg5k",
        "colab_type": "text"
      },
      "source": [
        "(...) St. Paul's cathedral in **London**, it was regarded (...) at that period, so **love**d and reverenced by the people (...)\n",
        "\n",
        "#### And again, let's retrieve the BookID and Volume to which this block of text belongs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM771h7fwg5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "London_love_df.loc[347374, ['bookid', 'volume']]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}